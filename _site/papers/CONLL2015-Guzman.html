<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="citation_title" content="Analyzing Optimization for Statistical Machine Translation: MERT Learns Verbosity, PRO Learns Length
" >
    
    
    <meta name="citation_author" content="Francisco Guzmán" >
    
    <meta name="citation_author" content=" Preslav Nakov" >
    
    <meta name="citation_author" content=" Stephan Vogel" >
    
    <meta name="citation_publication_date" content="2015">
    <meta name="citation_journal_title" content="Proceedings of the Nineteenth Conference on Computational Natural Language Learning (CoNLL)">
    
    
    <meta name="citation_firstpage" content="62">
    <meta name="citation_lastpage" content="72">
    
    <meta name="citation_pdf_url" content="/papers/CONLL2015-Guzman.pdf">
    
    <title>Analyzing Optimization for Statistical Machine Translation: MERT Learns Verbosity, PRO Learns Length
</title>

    <link href="http://0.0.0.0:4000/css/bootstrap.min.css" rel="stylesheet" media="screen">
    <link href="http://0.0.0.0:4000/css/bootstrap-glyphicons.css" rel="stylesheet">
    <link href="http://0.0.0.0:4000/css/style.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-61784189-1', 'auto');
      ga('send', 'pageview');

    </script>
        <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

    <!-- MathJax
    <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script> -->

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <!-- JavaScript plugins (requires jQuery) -->
    <script src="http://code.jquery.com/jquery.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="http://0.0.0.0:4000/js/bootstrap.min.js"></script>

    <div class="container">
      <div class="row">
        <div class="col-sm-2">
          <br/><br/>
<img src="http://0.0.0.0:4000/img/nav/paco2.jpg" class="img-responsive" alt="paco2"/>
<ul class="nav navbar-inverse">
  <li>
    <a href="http://0.0.0.0:4000/index.html">Home</a>
  </li>
  <li>
    <a href="http://0.0.0.0:4000/papers.html">Papers &amp; Talks</a>
  </li>
  <li>
    <a href="http://0.0.0.0:4000/projects.html">Projects</a>
  </li>
  <li>
    <a href="http://0.0.0.0:4000/mentoring.html">Mentoring</a>
  </li>
  <!-- <li>
    <a href=".html">Collaborators</a>
  </li>-->
  <li>
    <a href="http://0.0.0.0:4000/cv.html">CV</a>
  </li>
</ul>


        </div>
        <div class="col-sm-10">
          <div class="page-header">
      <h3>Analyzing Optimization for Statistical Machine Translation: MERT Learns Verbosity, PRO Learns Length
 </h3>
      <h4>Francisco Guzmán, Preslav Nakov, Stephan Vogel </h4>
</div>
<div class="media">	  
	We study the impact of source length and verbosity of the tuning dataset on the performance of parameter optimizers such as MERT and PRO for statistical machine translation. In particular, we test whether the verbosity of the resulting translations can be modified by varying the length or the verbosity of the tuning sentences. We find that MERT learns the tuning set verbosity very well, while PRO is sensitive to both the verbosity and the length of the source sentences in the tuning set; yet, overall PRO learns best from high-verbosity tuning datasets. Given these dependencies, and potentially some other such as amount of reordering, number of unknown words, syntactic complexity, and evaluation measure, to mention just a few, we argue for the need of controlled evaluation scenarios, so that the selection of tuning set and optimization strategy does not overshadow scientific advances in modeling or decoding. In the mean time, until we develop such controlled scenarios, we recommend using PRO with a large verbosity tuning set, which, in our experiments, yields highest BLEU across datasets and language pairs.

</div>
<div   class="media" >
  <a class="pull-left thumbnail"  href="/papers/CONLL2015-Guzman.pdf" >
    
    <img src="http://0.0.0.0:4000/img/paper/CONLL2015-Guzman.jpg" alt=""/>
    
  </a>
  <div class="media-body"  >
      <strong><a href="/papers/CONLL2015-Guzman.html">Analyzing Optimization for Statistical Machine Translation: MERT Learns Verbosity, PRO Learns Length
</a></strong><br/>
    Francisco Guzmán, Preslav Nakov, Stephan Vogel.
    
         In 
        
          <a href="http://www.conll.org/2015">
            <span class="glyphicon glyphicon-globe"></span>
          </a>
        
          <i>Proceedings of the Nineteenth Conference on Computational Natural Language Learning (CoNLL)</i>, pages 62-72, 
      
    2015.<br/>
    
     <a href="/papers/CONLL2015-Guzman.pdf" class="label label-success">PDF</a>
    
    
      <a data-toggle="modal" href="#abstractCONLL2015-Guzman" class="label label-default">Abstract</a>
      <!-- Modal -->
      <div class="modal fade" id="abstractCONLL2015-Guzman" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">Analyzing Optimization for Statistical Machine Translation: MERT Learns Verbosity, PRO Learns Length
</h4>
            </div>
            <div class="modal-body">
              We study the impact of source length and verbosity of the tuning dataset on the performance of parameter optimizers such as MERT and PRO for statistical machine translation. In particular, we test whether the verbosity of the resulting translations can be modified by varying the length or the verbosity of the tuning sentences. We find that MERT learns the tuning set verbosity very well, while PRO is sensitive to both the verbosity and the length of the source sentences in the tuning set; yet, overall PRO learns best from high-verbosity tuning datasets. Given these dependencies, and potentially some other such as amount of reordering, number of unknown words, syntactic complexity, and evaluation measure, to mention just a few, we argue for the need of controlled evaluation scenarios, so that the selection of tuning set and optimization strategy does not overshadow scientific advances in modeling or decoding. In the mean time, until we develop such controlled scenarios, we recommend using PRO with a large verbosity tuning set, which, in our experiments, yields highest BLEU across datasets and language pairs.

            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->

    
    
      <a data-toggle="modal" href="#bibtexCONLL2015-Guzman" class="label label-danger">BibTex</a>
      <!-- Modal -->
      <div class="modal fade" id="bibtexCONLL2015-Guzman" tabindex="-1" role="dialog" aria-hidden="true"> <div class="modal-dialog">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
              <h4 class="modal-title">Analyzing Optimization for Statistical Machine Translation: MERT Learns Verbosity, PRO Learns Length
</h4>
            </div>
            <div class="modal-body">
              <code style="white-space: pre-wrap; align: left">
                @InProceedings{guzman-nakov-vogel:2015:CoNLL, author    = {Guzm\'{a}n, Francisco  and  Nakov, Preslav  and  Vogel, Stephan}, title     = {Analyzing Optimization for Statistical Machine Translation: MERT Learns Verbosity, PRO Learns Length}, booktitle = {Proceedings of the Nineteenth Conference on Computational Natural Language Learning}, month     = {July}, year      = {2015}, address   = {Beijing, China}, publisher = {Association for Computational Linguistics}, pages     = {62--72}, url       = {http://www.aclweb.org/anthology/K15-1007}, abstract = {We study the impact of source length and verbosity of the tuning dataset on the performance of parameter optimizers such as MERT and PRO for statistical machine translation. In particular, we test whether the verbosity of the resulting translations can be modified by varying the length or the verbosity of the tuning sentences. We find that MERT learns the tuning set verbosity very well, while PRO is sensitive to both the verbosity and the length of the source sentences in the tuning set; yet, overall PRO learns best from high-verbosity tuning datasets.
  Given these dependencies, and potentially some other such as amount of reordering, number of unknown words, syntactic complexity, and evaluation measure, to mention just a few, we argue for the need of controlled evaluation scenarios, so that the selection of tuning set and optimization strategy does not overshadow scientific advances in modeling or decoding. In the mean time, until we develop such controlled scenarios, we recommend using PRO with a large verbosity tuning set, which, in our experiments, yields highest BLEU across datasets and language pairs.}
  }

              </code>
            </div>
          </div><!-- /.modal-content -->
        </div><!-- /.modal-dialog -->
      </div><!-- /.modal -->
    
    
    
      <a href="http://0.0.0.0:4000//media/CONLL2015-Guzman.pdf" class="label label-info">Slides</a>
    
    
    
    
  </div>
</div>



</div>
        </div>
        <div class="col-sm-15">


        </div>
      </div>
      <footer class="text-center text-muted">
        <hr/>
        Last updated January 29, 2017.<br/>
        Created with
        <a href="http://git-scm.com/">git</a>,
        <a href="http://jekyllrb.com">jekyll</a>,
        <a href="http://getbootstrap.com/">bootstrap</a>,
        and <a href="http://www.sublimetext.com/">sublime text</a>.<br/>
        Website template available at <a href="https://github.com/guzmanhe/guzmanhe.github.io"> github </a>
        <br/><br/>
      </footer>
    </div>
  </body>
</html>
